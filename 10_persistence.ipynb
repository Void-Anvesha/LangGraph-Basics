{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e05f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "#InMemorySaver is a checkpointer that saves the state of the graph in memory. It is useful for testing and debugging.\n",
    "#It is used to implement persistence in the graph, which allows us to save the state of the graph and load it later.\n",
    "#Saves state in RAM\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5298d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e3507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b70919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_joke(state: JokeState):\n",
    "\n",
    "    prompt = f'generate a joke on the topic {state[\"topic\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'joke': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144095c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(state: JokeState):\n",
    "\n",
    "    prompt = f'write an explanation for the joke - {state[\"joke\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'explanation': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5d3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('generate_joke', generate_joke)\n",
    "graph.add_node('generate_explanation', generate_explanation)\n",
    "\n",
    "graph.add_edge(START, 'generate_joke')\n",
    "graph.add_edge('generate_joke', 'generate_explanation')\n",
    "graph.add_edge('generate_explanation', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dcb1da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': 'Why did the pizza get a job as a motivational speaker?\\n\\nBecause it always knew how to **slice** through problems!',\n",
       " 'explanation': 'This joke is a **pun**, playing on the double meaning of the word \"slice.\"\\n\\nHere\\'s the breakdown:\\n\\n1.  **Literal Meaning (Pizza):** Pizza is something that is literally **sliced** into pieces before it\\'s eaten. It\\'s a fundamental characteristic of pizza.\\n\\n2.  **Figurative Meaning (Problem Solving):** The phrase \"to **slice through problems**\" is an idiom. It means to effectively and decisively deal with difficulties, to cut through complexity, or to overcome obstacles with ease.\\n\\nThe humor comes from the joke attributing the *literal* action of pizza (being sliced) to the *figurative* ability of a good motivational speaker (helping people \"slice through\" their problems). It\\'s a silly, unexpected connection that makes you groan and chuckle. The pizza is \"good at its job\" because its very nature involves \"slicing.\"'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data is stored against the thread_id in the checkpointer. We can use the same thread_id to retrieve the state of the graph later.\n",
    "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "workflow.invoke({'topic':'pizza'}, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b9bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': 'Why did the pizza get a job as a motivational speaker?\\n\\nBecause it always knew how to **slice** through problems!', 'explanation': 'This joke is a **pun**, playing on the double meaning of the word \"slice.\"\\n\\nHere\\'s the breakdown:\\n\\n1.  **Literal Meaning (Pizza):** Pizza is something that is literally **sliced** into pieces before it\\'s eaten. It\\'s a fundamental characteristic of pizza.\\n\\n2.  **Figurative Meaning (Problem Solving):** The phrase \"to **slice through problems**\" is an idiom. It means to effectively and decisively deal with difficulties, to cut through complexity, or to overcome obstacles with ease.\\n\\nThe humor comes from the joke attributing the *literal* action of pizza (being sliced) to the *figurative* ability of a good motivational speaker (helping people \"slice through\" their problems). It\\'s a silly, unexpected connection that makes you groan and chuckle. The pizza is \"good at its job\" because its very nature involves \"slicing.\"'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113399-664f-6505-8002-4b5add7bdce9'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-26T17:35:48.245837+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113399-2f0c-6cb1-8001-4992d33fa01e'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To know the current state of the graph, we can use the get_state method of the workflow. It will return the current state of the graph along with the data stored in the checkpointer.\n",
    "workflow.get_state(config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a815be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': 'Why did the pizza get a job as a motivational speaker?\\n\\nBecause it always knew how to **slice** through problems!', 'explanation': 'This joke is a **pun**, playing on the double meaning of the word \"slice.\"\\n\\nHere\\'s the breakdown:\\n\\n1.  **Literal Meaning (Pizza):** Pizza is something that is literally **sliced** into pieces before it\\'s eaten. It\\'s a fundamental characteristic of pizza.\\n\\n2.  **Figurative Meaning (Problem Solving):** The phrase \"to **slice through problems**\" is an idiom. It means to effectively and decisively deal with difficulties, to cut through complexity, or to overcome obstacles with ease.\\n\\nThe humor comes from the joke attributing the *literal* action of pizza (being sliced) to the *figurative* ability of a good motivational speaker (helping people \"slice through\" their problems). It\\'s a silly, unexpected connection that makes you groan and chuckle. The pizza is \"good at its job\" because its very nature involves \"slicing.\"'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113399-664f-6505-8002-4b5add7bdce9'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-26T17:35:48.245837+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113399-2f0c-6cb1-8001-4992d33fa01e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': 'Why did the pizza get a job as a motivational speaker?\\n\\nBecause it always knew how to **slice** through problems!'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113399-2f0c-6cb1-8001-4992d33fa01e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-02-26T17:35:42.451422+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113398-da3f-686b-8000-8b1712c970d8'}}, tasks=(PregelTask(id='710aeb30-c251-5c3c-2ab4-033fdf7f1735', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'This joke is a **pun**, playing on the double meaning of the word \"slice.\"\\n\\nHere\\'s the breakdown:\\n\\n1.  **Literal Meaning (Pizza):** Pizza is something that is literally **sliced** into pieces before it\\'s eaten. It\\'s a fundamental characteristic of pizza.\\n\\n2.  **Figurative Meaning (Problem Solving):** The phrase \"to **slice through problems**\" is an idiom. It means to effectively and decisively deal with difficulties, to cut through complexity, or to overcome obstacles with ease.\\n\\nThe humor comes from the joke attributing the *literal* action of pizza (being sliced) to the *figurative* ability of a good motivational speaker (helping people \"slice through\" their problems). It\\'s a silly, unexpected connection that makes you groan and chuckle. The pizza is \"good at its job\" because its very nature involves \"slicing.\"'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113398-da3f-686b-8000-8b1712c970d8'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-02-26T17:35:33.559306+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113398-da3a-69d0-bfff-b24dd73916a2'}}, tasks=(PregelTask(id='4c776da5-7d64-a066-b759-3bf0a43fc43a', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did the pizza get a job as a motivational speaker?\\n\\nBecause it always knew how to **slice** through problems!'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113398-da3a-69d0-bfff-b24dd73916a2'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-02-26T17:35:33.557294+00:00', parent_config=None, tasks=(PregelTask(id='a08f5dfc-befd-5968-a770-931949752944', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get intermediate state value of thread_id \"1\", we can use the get_state_history method of the workflow. It will return the history of states of the graph along with the data stored in the checkpointer.\n",
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01e0cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'batman',\n",
       " 'joke': \"What's Batman's favorite part of a joke?\\n\\nThe punchline!\",\n",
       " 'explanation': 'This joke plays on the **double meaning of the word \"punchline.\"**\\n\\nHere\\'s the breakdown:\\n\\n1.  **Standard Meaning of \"Punchline\":** In the context of a joke, the \"punchline\" is the final phrase or sentence that delivers the humor, the unexpected twist, or the funny conclusion. It\\'s the part that makes you laugh.\\n\\n2.  **The Batman Connection:** Batman is a superhero famous for fighting crime. His primary method of doing so often involves physical combat, where he literally **\"punches\"** villains.\\n\\nThe joke makes a pun by suggesting that Batman\\'s \"favorite part\" isn\\'t just the humorous ending of a story, but the literal act of delivering a **\"punch\"** (as in a fistfight) – something he does very well and very often in his crime-fighting career.\\n\\nThe humor comes from the unexpected twist of applying a word from the world of comedy (\"punchline\") to a literal action from Batman\\'s world (\"punch\").'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "workflow.invoke({'topic':'batman'}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6029e056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': 'Why did the pizza get a job as a motivational speaker?\\n\\nBecause it always knew how to **slice** through problems!', 'explanation': 'This joke is a **pun**, playing on the double meaning of the word \"slice.\"\\n\\nHere\\'s the breakdown:\\n\\n1.  **Literal Meaning (Pizza):** Pizza is something that is literally **sliced** into pieces before it\\'s eaten. It\\'s a fundamental characteristic of pizza.\\n\\n2.  **Figurative Meaning (Problem Solving):** The phrase \"to **slice through problems**\" is an idiom. It means to effectively and decisively deal with difficulties, to cut through complexity, or to overcome obstacles with ease.\\n\\nThe humor comes from the joke attributing the *literal* action of pizza (being sliced) to the *figurative* ability of a good motivational speaker (helping people \"slice through\" their problems). It\\'s a silly, unexpected connection that makes you groan and chuckle. The pizza is \"good at its job\" because its very nature involves \"slicing.\"'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113399-664f-6505-8002-4b5add7bdce9'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-26T17:35:48.245837+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113399-2f0c-6cb1-8001-4992d33fa01e'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90304c9e",
   "metadata": {},
   "source": [
    "*FAULT TOLERANCE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c478f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import TypedDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d38cc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the state\n",
    "class CrashState(TypedDict):\n",
    "    input: str\n",
    "    step1: str\n",
    "    step2: str\n",
    "    step3 : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a2ca02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define steps\n",
    "def step_1(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 1 executed\")\n",
    "    return {\"step1\": \"done\", \"input\": state[\"input\"]}\n",
    "\n",
    "def step_2(state: CrashState) -> CrashState:\n",
    "    print(\"⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\")\n",
    "    time.sleep(1000)  # Simulate long-running hang\n",
    "    return {\"step2\": \"done\"}\n",
    "\n",
    "def step_3(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 3 executed\")\n",
    "    return {\"step3\": \"done\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ab89564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build the graph\n",
    "builder = StateGraph(CrashState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "builder.set_entry_point(\"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df111c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Running graph: Please manually interrupt during Step 2...\n",
      "✅ Step 1 executed\n",
      "⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"▶️ Running graph: Please manually interrupt during Step 2...\")\n",
    "    graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "except KeyboardInterrupt:\n",
    "    print(\"❌ Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc90f0",
   "metadata": {},
   "source": [
    "*TIME TRAVEL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7043aab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TIME TRAVEL : We can now retrieve the state of the graph at the point of interruption and resume execution from there.\n",
    "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488586d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyInputError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoint_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1f06cc6e-7232-6cb1-8000-f71609e6cec5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anvesha Rastogi\\Desktop\\LANGRAPH\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anvesha Rastogi\\Desktop\\LANGRAPH\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2582\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2579\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2580\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2582\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2583\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2606\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2610\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2611\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anvesha Rastogi\\Desktop\\LANGRAPH\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1044\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anvesha Rastogi\\Desktop\\LANGRAPH\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:670\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys, updated_channels)\u001b[39m\n\u001b[32m    668\u001b[39m     \u001b[38;5;28mself\u001b[39m._put_checkpoint({\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_nested:\n",
      "\u001b[31mEmptyInputError\u001b[39m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3d20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
